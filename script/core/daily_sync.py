import baostock as bs
import pandas as pd
from sqlalchemy import create_engine, text
import numpy as np
import os
from datetime import datetime

# 1. å±è”½ä»£ç†
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
os.environ['all_proxy'] = ''

# 2. æ•°æ®åº“é…ç½® (ç¡®è®¤æ•°æ®åº“åä¸º dkh)
engine = create_engine('mysql+pymysql://root:ddd%401234@127.0.0.1:3306/dkh')
def daily_sync_task():
    bs.login()
    print(f"[{datetime.now()}] å¯åŠ¨æ¯æ—¥åŒæ­¥ä»»åŠ¡...")

    # --- æ¨¡å— Aï¼šè·å–æ•°æ®åº“å½“å‰çŠ¶æ€ ---
    # æˆ‘ä»¬ä¸ä»…æ‹¿æœ€åä¸€å¤©ï¼Œè¿˜æ‹¿å€’æ•°ç¬¬äºŒå¤©ï¼Œç¡®ä¿å¤æƒæ ¡éªŒä¸‡æ— ä¸€å¤±
    sql = """
    SELECT a.code, a.date, a.close
    FROM stock_history a
    INNER JOIN (
        SELECT code, MAX(date) as max_date FROM stock_history GROUP BY code
    ) b ON a.code = b.code AND a.date >= DATE_SUB(b.max_date, INTERVAL 7 DAY)
    ORDER BY a.code, a.date ASC
    """
    with engine.connect() as conn:
        all_db_data = pd.read_sql(text(sql), con=conn)
    
    stock_groups = all_db_data.groupby('code')
    total = len(stock_groups)
    fields = "date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,peTTM,pbMRQ,psTTM,pcfNcfTTM,isST"
    today_str = datetime.now().strftime("%Y-%m-%d")

    for i, (code, group) in enumerate(stock_groups):
        db_last_row = group.iloc[-1]
        db_last_date = db_last_row['date']
        db_last_close = float(db_last_row['close'])
        db_prev_close = float(group.iloc[-2]['close']) if len(group) >= 2 else None

        try:
            # æŠ“å–ï¼šä»æ•°æ®åº“æœ€åä¸€å¤©å¼€å§‹ï¼Œåˆ°ä»Šå¤©ä¸ºæ­¢
            rs = bs.query_history_k_data_plus(code, fields, 
                                             start_date=db_last_date.strftime("%Y-%m-%d"), 
                                             end_date=today_str, 
                                             frequency="d", adjustflag="2")
            
            api_list = []
            while (rs.error_code == '0') & rs.next():
                api_list.append(rs.get_row_data())
            
            if not api_list: continue # æ²¡æœ‰æ–°æ•°æ®ï¼Œè·³è¿‡

            df_api = pd.DataFrame(api_list, columns=rs.fields)
            for col in ['close', 'preclose']:
                df_api[col] = pd.to_numeric(df_api[col], errors='coerce')

            # --- æ¨¡å— Bï¼šè‡ªåŠ¨ä¿®å¤é€»è¾‘ (å‘ç°æ•°æ®æ–­è£‚æ—¶è§¦å‘) ---
            is_need_fix = False
            api_last_day_close = float(df_api.iloc[0]['close'])
            
            # æ ¡éªŒ 1ï¼šå¦‚æœ API ä¼ å›çš„â€œæœ€åä¸€å¤©â€ä»·æ ¼å’Œåº“é‡Œå¯¹ä¸ä¸Š
            if abs(api_last_day_close - db_last_close) > 0.01:
                is_need_fix = True
            
            # æ ¡éªŒ 2ï¼šå¦‚æœ API çš„æ˜¨æ”¶å’Œåº“é‡Œçš„å‰ä¸€å¤©å¯¹ä¸ä¸Š (è§£å†³å…´ä¸šé“¶è¡Œåˆ†çº¢é—®é¢˜)
            if not is_need_fix and db_prev_close is not None:
                api_last_day_preclose = float(df_api.iloc[0]['preclose'])
                if abs(api_last_day_preclose - db_prev_close) > 0.01:
                    is_need_fix = True

            if is_need_fix:
                print(f"ğŸš© [ä¿®å¤æ¨¡å¼] {code} æ•°æ®å¤±æ•ˆï¼Œé‡åˆ·å†å²...")
                full_rebuild_stock(code, fields, today_str)
                continue # ä¿®å¤å®Œç›´æ¥è·³è¿‡ï¼Œå› ä¸ºæ–°æ•°æ®å·²ç»åŒ…å«åœ¨é‡åˆ·é‡Œäº†

            # --- æ¨¡å— Cï¼šå¢é‡æ’å…¥é€»è¾‘ (æ­£å¸¸äº¤æ˜“æ—¥è¡¥å…¨) ---
            # å¦‚æœ df_api é•¿åº¦å¤§äº 1ï¼Œè¯´æ˜é™¤äº†â€œç”¨æ¥å¯¹æ¯”çš„é‚£å¤©â€ï¼Œåé¢è¿˜æœ‰â€œæ–°çš„ä¸€å¤©â€æˆ–â€œæ›´å¤šå¤©â€
            if len(df_api) > 1:
                # ã€è¿™å°±æ˜¯ä½ è¦æ‰¾çš„æ–°æ•°æ®æ’å…¥ä»£ç å—ã€‘
                # æˆ‘ä»¬åˆ‡ç‰‡å–å‡ºä»ç¬¬ 1 è¡Œåˆ°æœ€åçš„æ‰€æœ‰è¡Œï¼ˆç¬¬ 0 è¡Œæ˜¯åº“é‡Œå·²æœ‰çš„ï¼‰
                df_new_rows = df_api.iloc[1:].copy()
                
                # æ•°æ®æ¸…æ´—ï¼šè½¬æ•°å­—ï¼Œå¤„ç†ç©ºå€¼
                for col in df_new_rows.columns:
                    if col not in ['date', 'code']:
                        df_new_rows[col] = pd.to_numeric(df_new_rows[col], errors='coerce')
                df_new_rows = df_new_rows.where(pd.notnull(df_new_rows), None)

                # æ‰§è¡Œæ’å…¥åˆ°æ•°æ®åº“
                df_new_rows.to_sql('stock_history', con=engine, if_exists='append', index=False)
                # print(f"âœ… [å¢é‡æ¨¡å¼] {code} æˆåŠŸè¡¥å…¨ {len(df_new_rows)} å¤©æ–°æ•°æ®")

            if i % 200 == 0:
                print(f"å½“å‰è¿›åº¦: {i}/{total}")

        except Exception as e:
            print(f"é”™è¯¯: {code} -> {e}")
            continue

    bs.logout()
    print("âœ¨ å…¨å¸‚åœºæ•°æ®åŒæ­¥ä»»åŠ¡å·²åœ†æ»¡ç»“æŸï¼")

def full_rebuild_stock(code, fields, end_date):
    """æŠŠè¯¥è‚¡çš„å†å²æ•°æ®å½»åº•æ¨å€’é‡æ¥"""
    rs = bs.query_history_k_data_plus(code, fields, start_date='2024-01-01', end_date=end_date, frequency="d", adjustflag="2")
    data = []
    while (rs.error_code == '0') & rs.next():
        data.append(rs.get_row_data())
    if data:
        df = pd.DataFrame(data, columns=rs.fields)
        for col in df.columns:
            if col not in ['date', 'code']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.where(pd.notnull(df), None)
        with engine.begin() as conn:
            conn.execute(text(f"DELETE FROM stock_history WHERE code='{code}'"))
            df.to_sql('stock_history', con=conn, if_exists='append', index=False)

if __name__ == "__main__":
    daily_sync_task()